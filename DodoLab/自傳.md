# 自我研究計畫

在自然語言處理中通常需要裁切過長的input序列，有時會把重要的資訊裁切掉，也會讓某些需要長序列預測的任務無法進行預測。如bert對於長文章無法進行完整的預測，雖然可以將長文章切成數個overlap的序列進行預測評估，但是這樣並沒有對原文章有個完整的預測。我想試著解決這個問題。
如果可以將整個model當成一個大型的RNN，試著將長文章切分的序列前加上一個代表連接的token，這個token代表上一個序列的預測結果，理論上來說在最後一個序列可以得到一個更為完整評估整個文章的預測結果。

- 將長文章切分為數個符合model input大小的序列
- 並在序列前加上一個特殊的token
  - 這個token 所代表的 embedding 向量會是上個序列的output
- 比較這個方法與現有的其他方法的結果（如將長序列切分為數個overlap的序列進行預測評估）