#	爬蟲

Requests get

```
import requests
data = requests.get(url+access_token)

```

將回傳的資料轉成json

```
jsondata = json.loads(data.text)
```

## UrlManager URL控制器
存取URL
### \_\_init\_\_
- 	new\_urls : 未爬取URL集合
- 	old\_urls : 已爬取URL集合

### has\_new\_url()
-	判斷是否有未爬取的URL
- 	return bool

### get\_new\_url()
-	回傳一個未爬取的URL
- 	return str

### add\_new\_url(url)
-	將新的URL添加到未爬取的URL集合中
- 	param url : 一個URL (str)

### add\_new\_urls(urls)
-	將新的URL添加到未爬取的URL集合中
- 	param urls : URL集合 (set())

### new\_urls\_size()
-	回傳new_urls的長度

### old\_urls\_size()
-	回傳old_urls的長度

### save\_progress(path, data)
-	儲存資料到指定檔案
- 	param path: 指定檔案的路徑 
-  	param data: 存到檔案的資料

### load_progerss(path)
-	從指定檔案讀取資料
- 	param path: 指定檔案的路徑

## HtmlDownloader 網頁下載器
下載網頁
### download(url)
-	從指定URL下載網頁
-	param url: 指定網頁的URL
-	return : str

## HtmlParser HTML解析器
將從 `HtmlDownloader` 取得的HTML進行解析。
**客制環節**

## DataOutput 資料儲存器

## SpiderMan