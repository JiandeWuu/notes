# Address

## 條列

- 題目特殊，目前缺乏真實使用者資料，使用假規則資料訓練，以不同的規則資料與少量的真實資料做評估。但是又跟一般的NER任務不太一樣，規則與文字多樣性跟一般NER任務來說太少。
- BiLSTM（長短期記憶模型）
  - 可以達到很棒的 performance，在規則上與文字理解上都有很好的效果，但是在對有一定差距的規則時的 performance 就不是很好。
  - 添加額外資料（都是Other的資料）加入訓練可以增加真實資料的 performance。可以推斷多看一點資料或文字是可以越貼近真實世界在文意的理解上也有所幫助。
- Bert
  - 雖然在一般的NER任務普遍 performance 會比 BiLSTM 來的更好，但是在這題目的實驗表明 performance 並沒有 BiLSTM 來的好。

## Abstract

地址為了後續使用，通常會經過將地址以行政層級切分的處理後再做使用，以便更準確得定位座標並去除不正確或是不必要的文字。ex: 高雄市前鎮區中安路1號，{City:高雄市, Dist:前鎮區, IdLocation:中安路, AddressNumber:1號}。

通常會使用正則表達式來處理這個任務，不過輸入的地址規則越多所需要設計的這正則表達式就越多，造成成本的不斷上升而且在使用者輸入後才新增正則表達式的規則是不合邏輯的。
所以需要我們需要一個方法替代甚至解決正則表達式所做不到的規則。

在這篇文章中我們試著使用深度學習中的NLP的NER任務的角度去處理解決這個程序，前後訓練與評估了BiLSTM、CRF、Bert等等的模型。

因為缺乏實際使用者輸入的資料且標注資料的成本龐大，後面訓練的模型都是使用內政部全台正規地址製造的假規則資料。

在後面我們對各個模型進行訓練與評估它們在詞意的理解、多種地址規則的適應性。

## 1 Introduction

地址資訊是一種在實務上重要的資訊，如果沒有**地理資訊**（座標）通常會將地址轉換成**地理資訊**方便運算與使用或是直接使用在資料分析上。所以就會需要一個將地址資料處理或提取出有效的地址資訊的方法，

放開來看這個處理這個任務跟NLP中NER任務是非常相似的

BiLSTM 就可以達到很棒的 performance，但是在規則上

## 還想做的實驗

- per training 研究
  - LSTM, Attention 做 self-per training 使用 not zero Nei 地址資料與額外資料，fine-tuning 使用not zero Nei 地址資料
