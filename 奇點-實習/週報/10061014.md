# 至本週三預計執行

1. 模型
   1. 開發
   2. 訓練
      1. 前後調換順序
      2. 挖空
   3. 目前的所有規則作表格對比（Bilstm CRF、bert)
2. 佈署測試

## 執行項目

1. 模型
   1. 研究
      1. 看論文
         1. How to Fine-Tune BERT for Text Classification?
            1. 進一步 pre-training
            2. 多任務的fine-tuning
            3. 用小size的data進行訓練
   2. 開發

   3. 訓練
      1. 全台資料
         1. 前後調換順序（完成）
         2. 挖空（完成）
   4. 目前的所有規則作表格對比（Bilstm CRF、bert)
2. 佈署測試

## 至下週三預計執行

1. 模型
   1. 研究
      1. 看論文
   2. 開發
      1. 進一步pre-training
      2. 用小size的data進行訓練
   3. 訓練
   4. 目前的所有規則作表格對比（Bilstm CRF、bert)
2. 佈署測試
